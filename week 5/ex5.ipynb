{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.optimize as coolNonLinOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    "\n",
    "These exercises will take you through: \\ \n",
    "1. non-linear optimization, where you will implement a non-linear triangulation\n",
    "2. checkerboard calibration, in real life with OpenCV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear optimization\n",
    "This exercise will take you through doing nonlinear optimization for triangulation of a single \\\n",
    "point. The same principles can be applied to more complex situations such as camera calibration, \\\n",
    "or situations where we lack a linear algoritm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct two camera matrices\n",
    "R1 = np.identity(3)\n",
    "R2 = np.identity(3)\n",
    "t1 = np.array([[0, 0, 1]]).T\n",
    "t2 = np.array([[0, 0, 20]]).T\n",
    "\n",
    "K1 = np.array([[700, 0, 600], [0, 700, 400], [0, 0, 1]])\n",
    "K2 = np.array([[700, 0, 600], [0, 700, 400], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Both cameras observe the 3D point Q\n",
    "Q = np.array([[1, 1, 0]]).T\n",
    "Qh = np.vstack((Q, np.ones(len(Q[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Projection matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "P1 = K1@np.hstack((R1, t1))\n",
    "P2 = K2@np.hstack((R2, t2))\n",
    "\n",
    "### Projections\n",
    "q1h = P1 @ Qh\n",
    "q2h = P2 @ Qh\n",
    "### Inhomogenous coordinates\n",
    "q1 = q1h[0:2, :]/q1h[2, :]\n",
    "q2 = q2h[0:2, :]/q2h[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1300.]\n",
      " [1100.]] \n",
      " [[635.]\n",
      " [435.]]\n"
     ]
    }
   ],
   "source": [
    "print(q1,\"\\n\", q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Simulated noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_noisy = q1 + np.array([[1, -1]]).T\n",
    "q2_noisy = q2 + np.array([[1, -1]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectpoints(K, R, t, Q):\n",
    "    \"\"\"\n",
    "    Projects 3D points of an object to the 2D image plane of the camera.\n",
    "    Using homogenous coordinates the process can be done like this:\n",
    "            p_h = K*[R t]*P_h\n",
    "\n",
    "    Parameters:\n",
    "        - K: camera matrix - hold intrinsic camera info like focault distance and principal points\n",
    "        - R, t: pose of camera transformation; scale and transport object to the camera plane.\n",
    "        - Q: 3xn the n 3D points to be projected onto image plane.\n",
    "    \n",
    "    Returns: 2xn matrix of projected points\n",
    "    \"\"\"\n",
    "    \n",
    "    # First creates the [R t] Matrix\n",
    "    A = np.hstack((R, t))\n",
    "    # Then, translate Q to homogenous plane => 4xn matrix by adding s=1\n",
    "    B = np.vstack((Q, np.ones(len(Q[0]))))\n",
    "    # Solve the projection in homogenous plane \n",
    "    p_h = K@A@B\n",
    "    # Translate back to cartesian coordinates and return (divide all by s, then remove s)\n",
    "    return p_h[0:2, :]/p_h[2, :]\n",
    "\n",
    "def triangulate(q, P):\n",
    "    \"\"\"\n",
    "    Return the traingulation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    q: 2 x n numpy array\n",
    "        INHomogenous pixel coordinates q1... qn\n",
    "        One for each camera seeing the point.\n",
    "        At least two.\n",
    "    P: list of 3 x 4 numpy arrays\n",
    "        Projection matrices P1... Pn\n",
    "        For each pixel coordinate\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    Q: 3 x 1 numpy array\n",
    "        Triangulation of the point using the linear SVD algorithm\n",
    "    \"\"\"\n",
    "    _, n = q.shape # n = no. cameras has seen pixel.\n",
    "\n",
    "    # Prepare B matrix. Two rows for each camera n.\n",
    "    B = np.zeros((2 * n, 4))\n",
    "    for i in range(n):\n",
    "        B[2 * i: 2 * i + 2] = [\n",
    "            P[i][2, :] * q[0, i] - P[i][0, :],\n",
    "            P[i][2, :] * q[1, i] - P[i][1, :],\n",
    "        ]\n",
    "    # BQ = 0. Minimize using Svd.\n",
    "    _, _, vh = np.linalg.svd(B)\n",
    "    Q = vh[-1, :] # Q is ev. corresponding to the min. singular point.\n",
    "    return Q[:3].reshape(3, 1) / Q[3] # Reshape and scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_projected = triangulate(np.hstack((q1_noisy, q2_noisy)), [P1, P2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.01527507e+00]\n",
      " [9.85270570e-01]\n",
      " [2.85786810e-04]]\n",
      "Error/distance between Q and Q_tilde: 0.021221817353380575\n"
     ]
    }
   ],
   "source": [
    "print(Q_projected)\n",
    "print(\"Error/distance between Q and Q_tilde:\", np.linalg.norm(Q-Q_projected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Then reproject the points...\n",
    "Qh_projected  = np.vstack((Q_projected, np.ones(len(Q_projected[0]))))\n",
    "q1h_reprojected = P1 @ Qh_projected\n",
    "q2h_reprojected = P2 @ Qh_projected\n",
    "### Inhomogenous coordinates\n",
    "q1_reprojected = q1h_reprojected[0:2, :]/q1h_reprojected[2, :]\n",
    "q2_reprojected = q2h_reprojected[0:2, :]/q2h_reprojected[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total distance of the noisy points and their reprojected points\n",
      "Camera1: 13.433018988191378  pixels\n",
      "Camera2: 0.6717725840473774 pixels\n"
     ]
    }
   ],
   "source": [
    "print(\"Total distance of the noisy points and their reprojected points\")\n",
    "print(\"Camera1:\", np.linalg.norm(q1_reprojected-q1_noisy),\" pixels\\nCamera2:\", np.linalg.norm(q2_reprojected-q2_noisy), \"pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Nonlinear triangulation\n",
    "\n",
    "We are going to make a new function triangulate_nonlin that does triangulation using nonlinear \\\n",
    "optimization. It should take the same inputs as triangulate, i.e. a list of n pixel coordinates (q1, \\\n",
    "q2, . . . , qn), and a list of n projection matrices (P1, P2, . . . , Pn). \n",
    "\n",
    "Start by defining a helper-function inside triangulate_nonlin. \\\n",
    "This function, called compute_residuals, should take the parameters we want to optimize (in \\\n",
    "this case Q) as input, and should returns a vector of residuals (i.e. the numbers that we want to \\\n",
    "minimize the sum of squares of)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulate_nonlin(q, P):\n",
    "    \"\"\"\n",
    "    Return the traingulation using nonlinear optimization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    q: 2 x n numpy array\n",
    "        INHomogenous pixel coordinates q1... qn\n",
    "        One for each camera seeing the point.\n",
    "        At least two.\n",
    "    P: list of 3 x 4 numpy arrays\n",
    "        Projection matrices P1... Pn\n",
    "        For each pixel coordinate\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    Q: 3 x 1 numpy array\n",
    "        Triangulation of the point using the linear SVD algorithm,\n",
    "        combined with least square omptimizer\n",
    "    \"\"\"\n",
    "    # Initial guess using SVD\n",
    "    Q0 = triangulate(q, P)\n",
    "    Q0 = Q0.reshape(3)\n",
    "    \n",
    "    def compute_residuals(Q):\n",
    "        \"\"\"\n",
    "        In our case residuals is a vector of differences in the projections.\n",
    "        \"\"\"\n",
    "        Qh = np.vstack((Q.reshape(3,1), 1))\n",
    "        # n cameras\n",
    "        n = len(q[0])\n",
    "        residuals = np.zeros(shape=(2*n,))\n",
    "\n",
    "        for i in range(n):\n",
    "            qh_est = P[i] @ Qh\n",
    "            q_est = qh_est[0:2, :]/qh_est[2, :]\n",
    "            r = q_est - q[:,i].reshape(2, 1)\n",
    "\n",
    "            residuals[2*i] = r[0]\n",
    "            residuals[2*i+1] = r[1]\n",
    "\n",
    "\n",
    "        return residuals\n",
    "    Q = coolNonLinOptimizer.least_squares(compute_residuals, Q0)[\"x\"].reshape(3,1)\n",
    "    return  Q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_nonlin = triangulate_nonlin(np.hstack((q1_noisy, q2_noisy)), [P1, P2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only linear method: [1.01527507e+00 9.85270570e-01 2.85786810e-04]\n",
      "Using nonlinear methods: [1.00153898e+00 9.98546324e-01 4.27512498e-05]\n",
      "Real Q: [1 1 0]\n",
      "Q_nonlin difference:  0.0021174154572877386\n",
      "Q_linear difference:  0.021221817353380575\n"
     ]
    }
   ],
   "source": [
    "print(\"Using only linear method:\",Q_projected.flatten())\n",
    "print(\"Using nonlinear methods:\", Q_nonlin.flatten())\n",
    "print(\"Real Q:\", Q.flatten())\n",
    "print(\"Q_nonlin difference: \",  np.linalg.norm(Q_nonlin-Q))\n",
    "print(\"Q_linear difference: \",  np.linalg.norm(Q_projected-Q))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera calibration using openCV\n",
    "\n",
    "In the following exercises you will be calibrating your own camera. For this we suggest using a camera in your phone or similar. \\\n",
    "Disable HDR on your phone. If you have a phone with a wide angle camera, consider using this camera for the exercise (as more \\\n",
    "lens distortion is more fun and challenging). Remember to disable lens correction in your camera app before taking the pictures. \\\n",
    "If you get stuck with the OpenCV functions, start by looking it up in the OpenCV documentation.\n",
    "\n",
    "\n",
    "### 5.5 Calibration target\n",
    "\n",
    "Take one of the provided calibration targets or print your own. If you do not have access to a printer, \\\n",
    "showing the target on a laptop or tablet display is also an option, albeit less ideal due to the glass on top of the display, \\\n",
    "which can cause reflection and refraction. Using your calibration target, take pictures of it from many different angles. \\\n",
    "Make sure to have an image of it straight on and well lit, and try more extreme angles as well. Try to get every part \\\n",
    "of the frame covered. You should have around twenty images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6 Load and process images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb(path):\n",
    "    bgr_img = cv2.imread(path)\n",
    "    b,g,r = cv2.split(bgr_img)       # get b,g,r\n",
    "    image = cv2.merge([r,g,b])\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in range(20):\n",
    "    image = get_rgb(\"checkerboard/c%02d.jpg\" %i)\n",
    "    image = cv2.resize(image, (600, 400))\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for img in images:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7, 10))\n",
    "    if ret == True:\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (7, 10), corners,ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(800)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "becc7bcbb7a4199260879ba1a9630da63d2f52d521041d6c190802a5dc80d452"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
